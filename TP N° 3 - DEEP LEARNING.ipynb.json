{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "## Practical Deep Learning Tutorial with PyTorch - Tutorial N° 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2020-2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import grad\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Built ADALINE model using the nn.Module class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2632]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "        nn.Linear(2,2),\n",
    "        nn.ReLU()\n",
    "        )\n",
    "\n",
    "def modele(x) : \n",
    "    a = x.shape[1]\n",
    "    b = nn.Sequential(\n",
    "        nn.Linear(a,1),\n",
    "        nn.ReLU()\n",
    "        )\n",
    "    return b(x)\n",
    "\n",
    "X = torch.rand(1,7)\n",
    "modele(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ADALINE():\n",
    "    def __init__(self, input_size) : #On ne met pas output_size en argument, car c'est toujours 1. \n",
    "        self.weight = torch.rand(input_size, 1)\n",
    "        self.input_size = input_size\n",
    "    def forward(self, x) : \n",
    "        if x.shape[1] != self.input_size :\n",
    "            return 'error' \n",
    "        else :\n",
    "            return torch.mm(x, self.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2525, 0.9547, 0.3859, 0.8988, 0.4896, 0.6651, 0.5209])\n"
     ]
    }
   ],
   "source": [
    "a = ADALINE(7)\n",
    "print(a.weight[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'error'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(7,20)\n",
    "Y = a.forward(X)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Using 'iris.txt', create a binary datasets in 2-D : The last 100 instances of iris described only by the 2nd and 3rd features\n",
    "    \n",
    "    Split the dataset into traing and test sets (70%,30%) \n",
    "\n",
    "    Normalize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe le dataframe \n",
    "df = pd.read_csv('iris.txt', header = None)\n",
    "\n",
    "#On sélectionne les 100 dernieres données :\n",
    "df = df[50:150]\n",
    "\n",
    "# On enlève les 1ère et 4ème variables : \n",
    "df.columns = ['sepal0', 'sepal1','petal0', 'petal1', 'classe']\n",
    "df = df.drop(['sepal0', 'petal1'], axis =1)\n",
    "\n",
    "\n",
    "# Note pour moi : \n",
    "# On peut aussi faire : #iris = iris['sepal1','petal0', 'classe']\n",
    "# Attention, la fonction drop peut nécessiter le paramètre \"inplace = True\" dans certains cas.\n",
    "# A noter aussi que axis = 1 est pour les colonnes, axis = 0 pour les lignes.  \n",
    "# Et on aurait aussi pu faire : \n",
    "# del iris['sepal0']\n",
    "# del iris['petal1']\n",
    "\n",
    "\n",
    "# Normalisation du dataset : \n",
    "std_df= (df[['sepal1','petal0']] - np.average( df[['sepal1','petal0']] ) ) / (np.std(df[['sepal1','petal0']]))\n",
    "std_df['classe'] = df['classe']\n",
    "\n",
    "\n",
    "# get the locations\n",
    "X = df.iloc[:, 0:2]\n",
    "y = df.iloc[:, -1]\n",
    "  \n",
    "# split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=150)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "NOTES POUR MOI-MÊME :\n",
    "\n",
    "On peut aussi 'sélectionner' certaines variables ou données avec : \n",
    "iris.query(\"(classe == 'Iris-virginica' or classe == 'Iris-versicolor')\")\n",
    "Ici, c'est la même chose que : \n",
    "iris.query(\"(classe == 'Iris-virginica' or classe == 'Iris-versicolor') and (petal0>0)\") \n",
    "Je note ça juste pour bien me souvenir de la façon dont on utilise .query, ne pas prendre en compte. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal1                3.2\n",
      "petal0                4.5\n",
      "classe    Iris-versicolor\n",
      "Name: 51, dtype: object sepal1               2.7\n",
      "petal0               5.1\n",
      "classe    Iris-virginica\n",
      "Name: 101, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(iris.loc[51], iris.iloc[51])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Train the model : we will use MSELoss (mean squared error (squared L2 norm)) as loss function. The optimizer is SGD (Stochastic Gradient Descent) with learning rate 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Compute the model accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Built a Perceptron model using nn.Module class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Load the 'perceptron_toydata' dataset\n",
    "\n",
    "    Split the dataset into train and test sets\n",
    "    \n",
    "    Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Train the perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. evaluate the model (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the single-layer perceptron, the Multi Layer Perceptron models have hidden layers\n",
    "between the input and the output layers. After every hidden layer, an activation function \n",
    "is applied to introduce non-linearity. \n",
    "\n",
    "9. Built a simple Multi Layer Perceptron model withe one hidden layer. \n",
    "After the hidden layer, we will use ReLU as activation before the information is sent to the output layer.\n",
    "As an output activation function, we will use Sigmoid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Create a random datasets and assign binary labels {0,1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Define the model with input dimension 2 and hidden dimension 10. \n",
    "Since the task is to classify binary labels, we can use BCELoss (Binary Cross Entropy Loss) as loss function.\n",
    "The optimizer is SGD (Stochastic Gradient Descent) with learning rate 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Check the test loss before the model training and compare it with the test loss after the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. In order to improve the model, you can try out different parameter values for your\n",
    "hyperparameters(ie. hidden dimension size, epoch size, learning rates). You can also \n",
    "try changing the structure of your model (ie. adding more hidden layers) to see if your\n",
    "mode improves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
